#'@title Evaluates power for model matrix with a Monte Carlo simulation
#'
#'@description Evaluates design, given a run matrix, with a monte carlo simulation and returns
#'a data frame of parameter and effect powers.
#'
#'
#'@param RunMatrix The run matrix of the design.
#'@param model The model used in the evaluation.
#'@param alpha The type-I error.
#'@param nsim The number of simulations.
#'@param glmfamily String indicating the family of distribution for the glm function
#'(e.g. "gaussian", "binomial", "poisson")
#'@param rfunction Random number generator function for the response variable. Should be a function of the form f(X,b), where X is the
#'model matrix and b are the anticipated coefficients.
#'@param anticoef The anticipated coefficients for calculating the power. If missing, coefficients
#'will be automatically generated based on the delta argument.
#'
#'@param blockfuntion Random number generator for the noise due to blocks. See examples for details.
#'
#'@param blocknoise Vector of noise levels for each block, one element per blocking level. See examples for details.
#'@param delta The signal-to-noise ratio. Default 2. This specifies the difference between the high
#'and low levels. If you do not specify anticoef, the anticipated coefficients will be half of delta.
#'@param conservative Default FALSE. Specifies whether default method for generating
#'anticipated coefficents should be conservative or not. TRUE will give the most conservative
#'estimate of power by setting all but one level in a categorical factor's anticipated coefficients
#'to zero.
#'@param contrasts The contrasts to use for categorical factors. Defaults to contr.sum.
#'@param parallel Default FALSE. If TRUE, uses all cores available to speed up computation.
#'@return A data frame consisting of the parameters and their powers. The parameter estimates from the simulations are
#'stored in the 'estimates' attribute.
#'@import foreach doParallel
#'@export
#'@examples #We first generate a full factorial design using expand.grid:
#'factorialcoffee = expand.grid(cost=c(-1, 1),
#'                              type=as.factor(c("Kona", "Colombian", "Ethiopian", "Sumatra")),
#'                              size=as.factor(c("Short", "Grande", "Venti")))
#'
#'#And then generate the 21-run D-optimal design using gen_design.
#'
#'designcoffee = gen_design(factorialcoffee, model=~cost + type + size, trials=21, optimality="D")
#'
#'#To evaluate this design using a normal approximation, we just use eval_design
#'#(here using the default settings for contrasts, delta, and the anticipated coefficients):
#'
#'eval_design(RunMatrix=designcoffee, model=~cost + type + size, 0.05)
#'
#'#To evaluate this design with a Monte Carlo method, we enter the same information
#'#used in eval_design, with the addition of the number of simulations "nsim" and the distribution
#'#family used in fitting for the glm "glmfamily". For gaussian, binomial, expontial, and poisson
#'#families, a default random generating function (rfunction) will be supplied. If another glm
#'#family is used or the default random generating function is not adequate, a custom generating
#'#function can be supplied by the user.
#'
#'eval_design_mc(RunMatrix=designcoffee, model=~cost + type + size, alpha=0.05, nsim=10000,
#'               glmfamily="gaussian")
#'
#'#We see here we generate approximately the same parameter powers as we do
#'#using the normal approximation in eval_design. Like eval_design, we can also change
#'#delta to produce a different signal-to-noise ratio:
#'
#'eval_design_mc(RunMatrix=designcoffee, model=~cost + type + size, alpha=0.05,
#'               nsim=100, glmfamily="gaussian", delta=1)
#'
#'#Like eval_design, we can also evaluate the design with a different model than
#'#the one that generated the design.
#'eval_design_mc(RunMatrix=designcoffee, model=~cost + type, alpha=0.05,
#'               nsim=100, glmfamily="gaussian")
#'
#'#Here we evaluate the design using conservative anticipated coefficients:
#'eval_design_mc(RunMatrix=designcoffee, model=~cost + type + size, 0.05,
#'               nsim=100, glmfamily="gaussian", conservative=TRUE)
#'
#'#And here it is evaluated with interactions included:
#'eval_design_mc(RunMatrix=designcoffee,model=~cost + type + size + cost*type, 0.05,
#'               nsim=100, glmfamily="gaussian")
#'
#'#We can also set "parallel=TRUE" to turn use all the cores available to speed up
#'#computation.
#'\dontrun{eval_design_mc(RunMatrix=designcoffee, model=~cost + type + size, 0.05,
#'               nsim=10000, glmfamily="gaussian", parallel=TRUE)}
#'
#'#We can also evaluate split-plot designs. First, let us generate the split-plot design:
#'
#'vhtc = expand.grid(Store=as.factor(c("A","B")))
#'htc = expand.grid(Temp = c(1,-1))
#'
#'vhtcdesign = gen_design(factorial=vhtc, model=~Store, trials=6)
#'htcdesign = gen_design(factorial=htc, model=~Temp, trials=18, splitplotdesign=vhtcdesign, splitplotsizes=rep(3,6))
#'splitplotdesign = gen_design(factorial=factorialcoffee, model=~cost+type+size+size, trials=54,
#'                             splitplotdesign=htcdesign, splitplotsizes=rep(3,18))
#'
#'#Each block has an additional noise term associated with it in addition to the normal error term in the model.
#'#This is specified by a vector specifying the additional variance for each split-plot level. This is equivalent to
#'#specifying a variance ratio of one between the whole plots and the sub-plots for gaussian models.
#'#See the accompanying paper _____ for further technical details.
#'
#'#Evaluate the design. Note the decreased power for the blocking factors. If
#'eval_design_mc(RunMatrix=splitplotdesign, model=~Store+Temp+cost+type+size, alpha=0.05,
#'               nsim=100, glmfamily="gaussian", blocknoise = c(1,1))
#'
#'#We can also use this method to evaluate designs that cannot be easily
#'#evaluated using normal approximations. Here, we evaluate a design with a binomial response and see
#'#if we can detect the difference between each factor changing whether an event
#'#70% of the time or 90% of the time.
#'
#'factorialbinom = expand.grid(a=c(-1,1),b=c(-1,1))
#'designbinom = gen_design(factorialbinom,model=~a+b,trials=90,optimality="D",repeats=100)
#'
#'eval_design_mc(designbinom,~a+b,alpha=0.2,nsim=100,anticoef=c(1.5,0.7,0.7),
#'               glmfamily="binomial")
#'
#'#We can also use this method to determine power for poisson response variables.
#'#We design our test to detect if each factor changes the base rate of 0.2 by
#'#a factor of 2. We generate the design:
#'
#'factorialpois = expand.grid(a=as.numeric(c(-1,0,1)),b=c(-1,0,1))
#'designpois = gen_design(factorialpois, ~a+b, trials=90, optimality="D", repeats=100)
#'
#'eval_design_mc(designpois,~a+b,0.2,nsim=100,glmfamily="poisson", anticoef=c(log(0.2),log(2),log(2)))
#'
#'#where the anticipated coefficients are chosen to set the base rate at 0.2
#'#(from the intercept) as well as how each factor changes the rate (a factor of 2, so log(2)).
#'#We see here we need about 90 test events to get accurately distinguish the three different
#'#rates in each factor to 90% power.
eval_design_mc = function(RunMatrix, model, alpha, nsim, glmfamily,
                          blocknoise = NULL, rfunction=NULL, anticoef=NULL, delta=2,
                          conservative=FALSE, contrasts=contr.sum, parallel=FALSE) {
  glmfamilyname = glmfamily
  #------Auto-set random generating function----#
  if(is.null(rfunction)) {
    if(glmfamily == "gaussian") {
      rfunction = function(X,b,blockvector) {return(rnorm(n=nrow(X), mean = X %*% b + blockvector, sd = 1))}
    }
    if(glmfamily == "binomial") {
      rfunction = function(X,b,blockvector) {return(rbinom(n=nrow(X), size = 1 ,prob = 1/(1+exp(-(X %*% b + blockvector)))))}
    }
    if(glmfamily == "poisson") {
      rfunction = function(X,b,blockvector) {return(rpois(n=nrow(X), lambda = exp((X %*% b + blockvector))))}
    }
    if(glmfamily == "exponential") {
      glmfamily = Gamma(link="log")
      rfunction = function(X,b,blockvector) {return(rexp(n=nrow(X), rate = exp(X %*% b + blockvector)))}
    }
  }

  #---------- Generating model matrix ----------#
  #Remove columns from variables not used in the model
  RunMatrixReduced = reduceRunMatrix(RunMatrix,model)

  contrastslist = list()
  for(x in names(RunMatrixReduced[lapply(RunMatrixReduced, class) == "factor"])) {
    contrastslist[[x]] = contrasts
  }
  if(length(contrastslist) < 1) {
    contrastslist = NULL
  }

  #---------- Convert dot formula to terms -----#
  if((as.character(model)[2] == ".")) {
    model = as.formula(paste("~", paste(attr(RunMatrixReduced, "names"), collapse=" + "), sep=""))
  }

  ModelMatrix = model.matrix(model,RunMatrixReduced,contrasts.arg=contrastslist)
  #We'll need the parameter and effect names for output
  parameter_names = colnames(ModelMatrix)
  effect_names = c("(Intercept)", attr(terms(model), 'term.labels'))

  #-----Autogenerate Anticipated Coefficients---#
  if(missing(anticoef)) {
    anticoef = gen_anticoef(RunMatrixReduced, model, conservative=conservative)
  }
  if(length(anticoef) != dim(ModelMatrix)[2] && any(lapply(RunMatrixReduced,class)=="factor")) {
    stop("Wrong number of anticipated coefficients")
  }
  if(length(anticoef) != dim(ModelMatrix)[2] && !any(lapply(RunMatrixReduced,class)=="factor")) {
    anticoef = rep(1,dim(ModelMatrix)[2])
  }

  #-------------- Blocking errors --------------#
  blocking = FALSE
  blocknames = rownames(RunMatrix)
  blocklist = strsplit(blocknames,".",fixed=TRUE)

  if(any(lapply(blocklist,length) > 1)) {
    if(is.null(blocknoise)) {
      warning("Warning: blocknoise argument missing. Blocking ignored.")
    } else {
      blocking = TRUE
      blockstructure = do.call(rbind,blocklist)
      blockgroups = apply(blockstructure,2,blockingstructure)
    }
  }

  rblocknoise = function(noise,groups) {
    listblocknoise = list()
    for(i in 1:(length(groups)-1)) {
      blocktemp = list()
      for(j in 1:length(groups[[i]])) {
        row = rnorm(n=1,mean=0,sd=noise[i])
        blocktemp[[j]] = do.call(rbind, replicate(groups[[i]][j],row,simplify = FALSE))
      }
      listblocknoise[[i]] = do.call(rbind,blocktemp)
    }
    totalblocknoise = Reduce("+",listblocknoise)
    return(totalblocknoise)
  }

  #------------ Generate Responses -------------#

  responses = matrix(ncol=nsim,nrow=nrow(ModelMatrix))
  if(blocking) {
    for(i in 1:nsim) {
      responses[,i] = rfunction(ModelMatrix,anticoef*delta/2,rblocknoise(noise=blocknoise,groups=blockgroups))
    }
  } else {
    responses = replicate(nsim, rfunction(ModelMatrix,anticoef*delta/2,rep(0,nrow(ModelMatrix))))
  }
  #-------Update formula with random blocks------#

  if(!is.null(blocknoise)) {
    genBlockIndicators = function(blockgroup) {return(rep(1:length(blockgroup),blockgroup))}
    blockindicators = lapply(blockgroups,genBlockIndicators)
    blocknumber = length(blockgroups)-1
    randomeffects = c()
    for(i in 1:(length(blockgroups)-1)) {
      RunMatrixReduced[paste("Block",i,sep="")] = blockindicators[[i]]
      randomeffects = c(randomeffects, paste("( 1 | Block",i, " )", sep=""))
    }
    randomeffects = paste(randomeffects, collapse=" + ")
    blockform = paste("~. + ", randomeffects, sep="")
    #Adding random block variables to formula
    model = update.formula(model, blockform)
  }

  model_formula = update.formula(model, Y ~ .)
  RunMatrixReduced$Y = 1

  #---------------- Run Simulations ---------------#
  if(!parallel) {
    power_values = rep(0, ncol(ModelMatrix))
    effect_power_values = rep(0, length(effect_names))
    for (j in 1:nsim) {

      #simulate the data.
      RunMatrixReduced$Y = responses[,j]
      if (blocking) {
        if(glmfamilyname == "gaussian") {
          fit = lme4::lmer(model_formula, data=RunMatrixReduced, contrasts = contrastslist)
        } else {
          fit = lme4::glmer(model_formula, data=RunMatrixReduced, family=glmfamily, contrasts = contrastslist)
        }
      } else {
        if (glmfamilyname == "gaussian") {
          fit = lm(model_formula, data=RunMatrixReduced, contrasts = contrastslist)
        } else {
          fit = glm(model_formula, family=glmfamily, data=RunMatrixReduced, contrasts = contrastslist)
        }
      }
      #determine whether beta[i] is significant. If so, increment nsignificant
      pvals = extractPvalues(fit)
      power_values[pvals < alpha] = power_values[pvals < alpha] + 1
      effect_power_values = effect_power_values + effectSignificance(fit, alpha, attr(ModelMatrix, 'assign'))
    }
    #We are going to output a tidy data.frame with the results, so just append the effect powers
    #to the parameter powers. We'll use another column of that dataframe to label wether it is parameter
    #or effect power.
    power_values = c(power_values, effect_power_values)/nsim

  } else {
    cl <- parallel::makeCluster(parallel::detectCores())
    doParallel::registerDoParallel(cl, cores = parallel::detectCores())

    power_values = foreach::foreach (j = 1:nsim, .combine = "+", .packages = c("lme4")) %dopar% {
      power_values = rep(0, ncol(ModelMatrix))
      #simulate the data.
      RunMatrixReduced$Y = responses[,j]
      if (blocking) {
        if(glmfamilyname == "gaussian") {
          fit = lme4::lmer(model_formula, data=RunMatrixReduced, contrasts = contrastslist)
        } else {
          fit = lme4::glmer(model_formula, data=RunMatrixReduced, family=glmfamily, contrasts = contrastslist)
        }
      } else {
        if (glmfamilyname == "gaussian") {
          fit = lm(model_formula, data=RunMatrixReduced, contrasts = contrastslist)
        } else {
          fit = glm(model_formula, family=glmfamily, data=RunMatrixReduced,contrasts = contrastslist)
        }
      }
      #determine whether beta[i] is significant. If so, increment nsignificant
      pvals = extractPvalues(fit)
      power_values[pvals < alpha] = 1
      effect_power_values = effectSignificance(fit, alpha, attr(ModelMatrix, 'assign'))

      #We are going to output a tidy data.frame with the results, so just append the effect powers
      #to the parameter powers. We'll use another column of that dataframe to label wether it is parameter
      #or effect power.
      c(power_values, effect_power_values)
    }
    parallel::stopCluster(cl)
    power_values = power_values/nsim
  }
  #output the results (tidy data format)
  return(data.frame(parameters=c(parameter_names, effect_names),
                    type=c(rep("parameter.power.mc", length(parameter_names)),
                           rep("effect.power.mc", length(effect_names))),
                    power=power_values))
}
globalVariables('i')
